{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ameliabaier/opt/anaconda3/envs/ANLY555/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from datasketch import MinHash, MinHashLSHForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess will split a string of text into individual tokens/shingles based on whitespace.\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    tokens = text.lower()\n",
    "    tokens = tokens.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shingles (tokens) are: ['the', 'devil', 'went', 'down', 'to', 'georgia']\n"
     ]
    }
   ],
   "source": [
    "text = 'The devil went down to Georgia'\n",
    "print('The shingles (tokens) are:', preprocess(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Permutations\n",
    "permutations = 128\n",
    "\n",
    "#Number of Recommendations to return\n",
    "num_recommendations = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forest(data, perms):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    minhash = []\n",
    "    \n",
    "    for text in data['text']:\n",
    "        tokens = preprocess(text)\n",
    "        m = MinHash(num_perm=perms)\n",
    "        for s in tokens:\n",
    "            m.update(s.encode('utf8'))\n",
    "        minhash.append(m)\n",
    "        \n",
    "    forest = MinHashLSHForest(num_perm=perms)\n",
    "    \n",
    "    for i,m in enumerate(minhash):\n",
    "        forest.add(i,m)\n",
    "        \n",
    "    forest.index()\n",
    "    \n",
    "    print('It took %s seconds to build forest.' %(time.time()-start_time))\n",
    "    \n",
    "    return forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, database, perms, num_results, forest):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    tokens = preprocess(text)\n",
    "    m = MinHash(num_perm=perms)\n",
    "    for s in tokens:\n",
    "        m.update(s.encode('utf8'))\n",
    "        \n",
    "    idx_array = np.array(forest.query(m, num_results))\n",
    "    if len(idx_array) == 0:\n",
    "        return None # if your query is empty, return none\n",
    "    \n",
    "    result = database.iloc[idx_array]['title']\n",
    "    \n",
    "    print('It took %s seconds to query forest.' %(time.time()-start_time))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 25.51142930984497 seconds to build forest.\n"
     ]
    }
   ],
   "source": [
    "db = pd.read_csv('papers.csv')\n",
    "db['text'] = db['title'] + ' ' + db['abstract']\n",
    "forest = get_forest(db, permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.03361201286315918 seconds to query forest.\n",
      "\n",
      " Top Recommendation(s) is(are) \n",
      " 995     Neural Network Weight Matrix Synthesis Using O...\n",
      "5       Using a neural net to instantiate a deformable...\n",
      "5191    A Self-Organizing Integrated Segmentation and ...\n",
      "2069    Analytic Solutions to the Formation of Feature...\n",
      "2457    Inferring Neural Firing Rates from Spike Train...\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "num_recommendations = 5\n",
    "title = 'Using a neural net to instantiate a deformable model'\n",
    "result = predict(title, db, permutations, num_recommendations, forest)\n",
    "print('\\n Top Recommendation(s) is(are) \\n', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.022990942001342773 seconds to query forest.\n",
      "\n",
      " Top Recommendation(s) is(are) \n",
      " 7169    Asymptotics of Gradient-based Neural Network T...\n",
      "3       Bayesian Query Construction for Neural Network...\n",
      "6633    Neural Network Model Selection Using Asymptoti...\n",
      "652     Global Optimisation of Neural Network Models v...\n",
      "859         Neural Network Based Model Predictive Control\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# my test\n",
    "num_recommendations = 5\n",
    "title = 'Bayesian Query Construction for Neural Network Models'\n",
    "result = predict(title, db, permutations, num_recommendations, forest)\n",
    "print('\\n Top Recommendation(s) is(are) \\n', result)\n",
    "\n",
    "# the results seem similar to the input query, yes! "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d0e71dbd1f683d085d22da62e288a71fc28a2407039218eed1614b5a4aafdc96"
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 ('ANLY555')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
